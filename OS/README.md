# 운영체제

- [프로세스와 스레드](#프로세스와-스레드)
- [멀티 스레드](#멀티-스레드)
- [스케줄러](#스케줄러)
- [CPU 스케줄러](#CPU-스케줄러)
- [동기와 비동기(I/O)](#동기와-비동기)
- [프로세스 동기화](#프로세스-동기화)
- [메모리 관리 전략](#메모리-관리-전략)
- [가상 메모리](#가상-메모리)

## 프로세스와 스레드

> 프로세스(Process) 실행 중인 프로그램이 메모리에 적재 되어 CPU의 할당을 받는 것. 스레드(Thread)는 프로세스의 실행 단위.
> 프로세스 제어 블록(Process Control Block, PCB)은 OS 자료구조로 프로세스에 대한 중요한 정보를 저장한다. 프로세스 생성 = 고유한 PCB 생성

1. 프로세스 : OS로 부터 주소 공간, 파일, 메모리 등을 할당 받으며 이것들을 총칭한다. 프로세스 스택(함수의 매개변수, 복귀 주소, 로컬변수)과 데이터 섹션(전역 변수), 동적으로 할당되는 메모리 힙을 포함해서 프로세스라고한다.
2. 프로세스 제어블록(PCB) : 프로세스가 CPU를 할당받아 작업을 처리하다 프로세스 전환이 발생하면 진행 상황을 모두 PCB에 저장하고 CPU 반환, 추후
재할당시 PCB 저장 정보로 종료시점 부터 작업을 다시 수행
3. PCB 저장 정보 : 프로세스 식별자(Process ID, PID), 프로세스 상태(new, ready, running, waiting, terminated), 프로그램 카운터(다음에 실행 명령어 주소), CPU 레지스터, CPU 스케쥴링 정보(프로세스 우선순위, 스케쥴 큐에 대한 포인터 등), 메모리 관리(페이지 테이블, 세그먼트 테이블 등), 입출력 상태(할당된 입출력장치, open파일 목록), 어카운팅 정보(Use CPU Time, TimeLimit, 계정 번호등)
4. 스레드 : 프로세스의 주소 공간이나 자원을 공유함, 스레드는 스레드ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성된다. 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 열린 파일, 신호등 OS 자원을 공유한다.
5. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고, 자원 생성,관리의 중복을 최소화하여 수행능력을 향상 시키는 것을 멀티 스레딩이라 한다. 각 스레드는 독립 작업을 위해서 각자의 스택과 PC레지스터 값을 갖는다.
6. 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간
7. PC Register는 PC값을 저장하여 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다. 스레드는 CPU 를 할당받았다가 스케쥴러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억한다.

## 멀티 스레드

> 멀티 스레드, 멀티 프로세스 두가지 방법의 공통점은 여러가지 루틴을 동시에 실행하고자 한다는 것이다.

1. 멀티 스레딩은 멀티 프로세스에 비해서 메모리 공간과 시스템 자원 소모가 줄어든다. 스레드 간의 통신도 프로세스 보다 용이하게 전역 변수나 Heap으로 데이터를 주고 받을 수 있고, 스레드 context switch는 프로세스 와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
2. 결국 멀티 스레드 시스템이 멀티 프로세스 시스템 보다 throughtput이 향상 되고 자원 소모가 줄어들며 응답이 빠르다.
3.  멀티 스레드는 데이터와 힙 영역을 공유하기 때문에 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있기에 작업 처리와 자원 접근 을 컨트롤 하는 동기화 작업이 필요하다.
4. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상은 줄여야 한다.
5. 멀티 스레드는 멀티 프로세스 보다 적은 자원(메모리등)을 소모하고 문맥 전환이 빠르지만 하나의 스레드가 오류가 나면 다른 스레드까지 영향을 받아 종료 될 수 있다. 
6. 결국 멀티 프로세스는 안정성이 멀티 스레드보다 뛰어나며 자원소모가 심하고, 멀티 스레드는 자원 소모는 상대적으로 적은 대신 예외 상황의 안정성이나 동기화 문제 등 인프라적인 문제점이 존재한다.

## 스케줄러

> 스케줄러 어떤 프로세스에게 자원을 할당할지를 결정하는 운영체제 커널의 모듈.  
> 스케줄러에는 단기(cpu), 중기(메모리), 장기(작업) 스케줄러가 존재한다.  
> 프로세스를 스케줄링 하기 위한 Queue에는 세 가지 Job Queue : 현재 시스템 내 모든 프로세스 집합, Ready Queue : 현재 메모리 내에 있으면서 CPU를 기다리는 프로세스 집합, Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

1. 장기 스케줄러(Long-term Scheduler or Job Scheduler) : 어떤 프로세스에 메모리에 할당하여 Ready Queue로 보낼지 결정한다. 디스크 와 메모리 사이의 스케줄링, 실행중인 멀티 프로세스 제어(degree of Multiprogramming), New => Ready(In Memory), 수행 속도가 상대적으로 느려도 됨.
2. 현대 시분할 시스템(Time Sharing System)에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 Ready 상태가 된다.
3. 단기 스케줄러(Short-term Schduler or CPU Scheduler) : 어떤 프로세스에 CPU를 할당(scheduler dispatch)하여 Running 시킬지 결정한다. Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 Running시킬지 결정 Ready => Running => Waiting => Ready, 수행 속도가 충분히 빨라야함.
4. 중기 스케줄러(Medium-term Scheduler or Swapper) : 프로세스 중 일부러 부터 메모리를 통째로 빼앗아 디스크에 저장(Swap Out)하는 스케쥴러 여유공간을 마련한다. 프로세스에게서 memory 를 deallocate할 때는 봉쇄 상태를 가장 먼저 스왑시킨다.(CPU 획득할 가능성이 없어서) => 준비 큐로 이동하는 프로세스 스왑아웃, degree of Multiprogramming 제어, Ready => Suspended, 인 메모리 프로세스 조절 스케줄러
5. 중지 준비(suspenden ready) : 준비 상태의 프로세스가 중기 스케줄러에 의해 디스크로 swap out, 봉쇄 중지(suspenden block) : 봉쇄 상태의 프로세스가 중기 스케줄러에 의해 디스크로 swap out

## CPU 스케줄러

> 스케줄링시 고려사항 선점형(Preemptive), 비선점형(Non-Preemptive), CPU 집중 프로세스(CPU Bound Process), 입출력 집중 프로세스(I/O Bound Process), 전면 프로세스, 후면 프로세스  
> 프로세스 우선순위 커널 > 일반, 전면 > 후면, 대화 > 일괄처리, 입출력 집중 > CPU 집중

1. 선점형(Preemptive) : 프로세스 CPU를 가져 올 수 있어 효율적인 운영 가능 잦은 문맥 교환으로 오버헤드가 많이 발생한다.
2. 비선점형(Non-Preemptive) : 프로세스 CPU를 빼앗을 수 없어서 오버헤드가 상대적으로 적지만 배치에 따라 효율성 차이가 많이 난다.
3. CPU 집중 프로레스(CPU Bound Process) : CPU를 많이 사용하여 CPU Burst(실행 시간, 구간)가 많은 프로세스.
4. 입출력 집중 프로세스(I/O Bound Process) : 입출력을 많이 사용해 I/O Burst(처리 시간, 구간)가 많은 프로세스.
5. 전면 프로세스 : GUI 운영체제 화면 맨앞에 놓여 입출력등 사용자와의 상호작용이 가능한(상호작용 프로세스) 문서편집기 등의 프로세스
6. 후면 프로세스 : 사용자 입력 없이 작동하여 일괄 작업이 가능한(일괄작용 프로세스) 압출 등의 프로세스
7. CPU(단기, 저수준) 스케줄러의 스케줄링 대상은 Ready Queue에 있는 프로세스들이다.

### 스케줄링 알고리즘

1. FCFS(First Come First Served) : 큐에 들어온 순서대로 처리, 비선점형, 호위효과(Convoy Effect) : 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.
2. SJF(Shortest - Job - First) : CPU Burst Time이 짧은 순서대로 처리, 비선점형, 기아상태(Starvation) : 사용시간이 긴 프로세스가 극단적으로 CPU를 할당 받지못한다. 공평성에 지나치게 위배됨.
3. SRT(Shortest Remaining Time First) : 새로운 프로세스가 도착할때 마다 새로 스케줄링, 선점형 : 현재 프로세스 CPU Burst 보다 짧은 CPU Burst 프로세스가 도착하면 CPU를 뺏어 할당, 기아상태, CPU Burst time을 측정 할 수 없다.
4. 우선순위(Priority Scheduling) : 우선 순위(정수로 작을수록 높다.)가 높은 순서대로 처리, 선점형 : 다음 우선순위가 높으면 뺏긴다, 비선점형 : 더 높은 우선순위는 Ready Queue Head로, 기아상태, 무기한 봉쇄(Indefinite Blocking) : 실행 준비는 되었으나 CPU를 사용 못하는 프로세스를 CPU가 무한 대기하는 상태, 노화(Aging) : 아무리 우선 순위가 낮은 프로세스라도 오래 기다리면 순위를 높인다.
5. Round Robin : 각 프로세스는 동일한 할당 시간(Time Quantum)을 갖고 그 동안 처리하고 끝나지 않으면 선점(프로세스의 context를 save) 당하고 가장 뒤 순서를 가지기를 반복한다. CPU Burst가 랜덤인 프로세스들이 혼합시 효율적, 응답이 빨라지고 (프로세스 - 1)할당시간, 가장 공정한 스케줄링이다
6. 단 라운드 로빈의 Time Quantum이 너무 커지면 FCFS와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch 로 overhead 가 발생한다. 적당한 Time Quantum(보통 10 ~ 100ms)을 설정하는 것이 중요하다.
7. 다단계 큐 (Multi-level Queue) : Ready Queue를 여러개로 분류하여 각기 다른 알고리즘으로 처리, 프로세스 특성에 따라 영구적으로 할당, 큐와 큐사이의 스케줄링(우선순위, 시분할) 필요 
7. 다단계 피드백 큐 (Multi-level Feedback Queue) : 기존 다단계 큐가 프로세스의 큐 단위 이동을 막아서 오버헤드를 줄인 대신 융통성이 부족하다는 점을 개선하기 위한 방법, 프로세스가 큐 사이를 이동하는 것이 허용, 낮은 우선순위의 큐에서 너무 오래 대기하는 프로세스들은 높은 곳으로 이동(노화)하여 기아 상태를 예방.

## 동기와 비동기

> I/O 모델 특징은 Blocking, Non-Blocking, Asynchronous, Synchronous 가 있다.  
> IO 작업은 사용자 레벨에서는 직접 수행이 불가능하며, OS레벨에서 수행된다. 사용자 프로세스 => 커널(OS) IO요청.

1. Blocking I/O Model : User Level에 있던 APP이 시스템 함수를 호출(Context-Switing) I/O 완료후 반환 할때 APP 단 스레드의 block이 풀린다. IO 작업 동안 유저 프로세스를 중단한채 대기하기에 CPU자원 낭비가 심하다.(I/O작업동안은 CPU를 거의 안쓴다.)
2. Non-Blocking I/O Model : I/O Block 동안은 CPU를 거의 안쓰기에 CPU자원을 대기시키는 것은 낭비이고 이 점을 극복하기 위해서 나온 방법이다. 프로세스 중단 없이 결과(일종의 포인터)를 바로 반환 한후 폴링(polling) 방식으로 결과 데이터가 준비 되었는지 확인한다. 수많은 요청이 동시에 발생하는 경우 폴링 방식에 의해서 CPU 자원 소모가 심하다.
3. Multiplexing I/O Model : 블록킹 모델과 논 블로킹 모델을 골라쓰는 모델.
4. Signal-Driven I/O Model : 논 블로킹 모델에서의 폴링을 signal 방식으로 대체 한 방식, TCP에 부적합(신호 중복 및 반복 문제)
5. Asynchronous I/O Model(Event-Driven Model) : Non-Blocking에서 데이터를 폴링 방식이 아니라 이벤트 통지 방식으로 확인한다. I/O 작업 요청후 작업 중단없이 다른 작업을 하다 이벤트 통지(completion)를 받으면 그에 맞게 처리해준다. 시스템 call완료를 기다리지 않는다. 시스템콜 결과를 바로 반환하지 않는다.
6. Synchronous I/O Model : 비동기를 제외한 모든 모델은 동기 I/O모델.
7. 정해진 순서대로 차례 차례 작업을 처리 하는 걸 동기라고 부르고, 작업을 요청한후(백그라운드 스레드나, 이벤트 큐) 해당 작업을 대기하지 않고 다른 작업을 진행하다. 해당 작업이 완료 되면 그에 맞는 처리를 하는 방식을 비동기라 부른다. 

## 프로세스 동기화

> 임계 영역(Critical Section) : 멀티 스레딩에서의 동일한 자원을 동시에 접근하는 작업을 실행하는 코드 영역
> 프로세스 동기화는 사실상 임계 영역 문제(Critical Section Problem)를 어떤 프로토콜로 처리할 것인가다.

1. 프로세스 동기화는 3가지 기본 조건을 만족해야한다. 상호 배제(Mutual Exclusion) : 다른 프로세스가 임계 영역에서 실행중일때 다른 프로세스는 접근 금지, 진행(Progress) : 임계 영역 에서 실행 중인 프로세스가 없다면, 다른 프로세스가 유한한 시간 내에 임계 영역에 접근 가능, 한정된 대기(Bounded Waiting) : 프로세스의 임계 영역 진입에 대한 요청 이후에 다른 프로세스의 임계 영역 진입이 유한한 횟수로 제한되어 무한히 대기하지 않음

### 임계영역 문제 해결책

1. Lock : 하드웨어 차원에서 Lock을 건다. 임계 영역에 진입하는 프로세스에 LOCK을 부여하고 빠져나올 때 Lock을 방출 하여 상호 배제, 단 다중처리 환경에서는 시간효율성 측면에서 한계가 있음
2. 세마포(Semaphores) : 소프트웨어 차원에서 Lock을 건다. 임계 영역에 진입하는 프로세스를 관리하는 방법으로 크게 Counting, Binary 두 방식의 세마포가 존재한다. 단, 바쁜 대기(Busy Waiting), 교착상태(Deadlock)라는 문제점이 존재한다.
3. Counting Semaphores : 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용 된다. 자원의 갯수로 초기화하고 사용하면 세마포가 감소, 방출하면 증가
4. Binary Semaphores(MUTEX) : 상호배제(Mut, ex) 0과 1 사이의 값만으로 다중 프로세스들 사이의 임계 영역 문제를 해결하기 위해 사용된다.
5. 바쁜 대기(Busy Waiting) : Spin Lock(세마포 초기버전)에서 임계 영역에 진입 하는 프로세스는 Lock의 해제를 기다리며 진입코드를 반복 실행해서 Context Switching(CPU시간을 낭비) 한 것을 지칭한다. 진입이 실패한 프로세스를 Block을 통해서 대기시키고 CPU를 스케줄링 해서 해결 할 수 있다.
6. 교착 상태(Deadlock) : 세마포가 Ready Queue를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있는 상황을 지칭한다.
7. 교착 상태를 방지하려면 4가지 조건을 충족 해야한다. 상호 배제, 점유대기(Hold & Wait), 비선점(No Preemption), 순환 대기(Circular Wait)
8. 모니터(Monitor) : 고급 언어에서 주로 사용되는 설계 구조물이다. 코드를 서로 상호 배제 하게끔 만든 추상화 된 데이터 형태, 공유 자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다.(프로시저 호출) 자바에서 많이 사용 되는 방법, 임계 영역을 모니터로 지정하면, 모니터 내부의 프로세스들만 임계 영역에 접근 가능하고 나머지는 입장큐에서 대기시킨다.

## 메모리 관리 전략

> 프로세스는 독립된 메모리 공간을 갖고 운영체제 혹은 다른 프로세스의 메모리 공간에 접근 할 수 없는 제한이 걸려있다.
> 운영체제만이 운영 체제의 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.
> 메모리 관리 전략에서 중요한 키워드는 크게 4가지가 있다. Swapping, 단편화(Fragmentation), Paging, Segmentation

1. Swapping : 표준 Swapping 방식으로는 라운드 로빈 과 같은 스케줄링 다중 환경에서 CPU 할당 시간이 끝난 프로세스 메모리를 보조 기억 장치에서 내보내고, 다른 프로세스 메모리를 불러 들일 수 있다. Swap : 주 기억장치(RAM)으로 Swap-in, 보조 기억장치로 Swap-out, 디스크 전송시간이 많이 필요 메모리 공간이 부족할때 시작
2. 단편화 : 프로세스들이 메모리에 적재 되고 제거 되는 걸 반복 하다보면 프로세스들 사이의 사용하지 못하는 작은 자유 공간 늘어나서 메모리가 충분함에도 프로세스가 적재 되지 못하는 현상을 말한다. 크게 2가지로 나뉜다. 외부 단편화, 내부 단편화, 외부단편화를 해결하는 방법으로 압축이 있다.
3. 외부 단편화 : 물리 메모리 사이의 자유 공간이 분산 되어서 여유공간을 사용 할 수 없을때를 외부 단편화로 본다.
4. 내부 단편화 : 고정 분할 방식에서 프로세스가 실제로 사용해야 할 메모리보다 큰 메모리를 할당 받아서 남는 여유공간 을 내부 단편화로 본다.
5. 압축 : 외부 단편화를 해소하기 위해서 자유 공간을 모으는 방법, 프로세스를 정지시키고 한곳으로 모아서 자유공간을 확보하는 방법론이지만 매우 비 효율적이다.
6. Paging : 하나의 프로세스가 사용하는 메모리 공간의 연속성이라는 제약을 없애는 기법, 물리 메모리를 Frame(페이지 프레임), 논리 메모리(프로세스가 점유하는)를 page라 불리는 고정 크기의 블록으로 분리해서 보조 기억 장치의 페이지를 주 기억장치에 적재해서 사용하는 방법이다.
외부 단편화는 거의 사라지지만 내부 단편화 문제는 해결 되지 않는다.(페이지가 고정된 크기이기 때문)
7. Segmentation : 페이징과 다르게 서로 다른 크기의 세그먼트로 분할해서 사용자에게 세그먼트 번호와 변위를 합친 가상 주소와 세그먼트 테이블에 시작 물리주소 와 한계를 저장해서 메모리를 관리하는 방법, 내부 단편화 문제는 해결 되었지만 외부 단편화 문제는 해결 되지 않는다.

## 가상 메모리

> 다중 프로그래밍을 실현하기 위해서는 많은 프로세스를 동시에 메모리에 올려 두어야한다.  
> 가상 메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법  
> 프로그램이 물리 메모리 보다 커도 된다. 동시에 더 많은 프로그램을 실행 가능 해져 CPU이용률, 과 처리율이 높아짐

1. 가상 메모리 : 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것. 작은 메모리로도 큰 가상 주소 공간을 제공 가능하다.
2. 가상 주소 공간 : 메모리에 저장되는 논리적인 모습을 가상 메모리에 구현한 공간. 프로세스 => 가상 메모리 => 물리메모리 구조로 불필요한 물리메모리 절약가능
3. 요구 페이징(Demand Paging) : 프로그램 시작시 초기에 필요한 것들만 메모리에 적재하는 전략을 말한다. 페이지로 관리 되며 한번도 접근 되지 않은 페이지는 물리 메모리에 적재되지 않는다. 프로세스 내 개별 페이지들은 페이저(pager)에 의해 관리 되고 실제 필요한 페이지만 메모리로 적재함으로 시간 낭비와 메모리 낭비를 감소.
4. 페이지 교체 : 프로세스 동작 과정에서 필요한 페이지를 요청 하는 과정에서 페이지 부재(page fault)가 발생하면 보조 기억장치에서 페이지를 가져온다. 단 물리 메모리를 모두 사용 중이라면 페이지 교체가 이루어져야한다.(또는 강제 종료)

### 페이지 교체

> 물리 메모리가 모두 사용 중이라면 디스크에서 필요한 페이지 위치를 찾고, 빈 페이지 프레임을 찾는다.(페이지 교체 알고리즘으로 희생될(victim) 페이지 선택, 디스크에 기록 및 테이블 수정), 비워진 테이블 프레임에 새 페이지를 불러오고 테이블을 수정, 사용자 프로세스 재시작.  
> 페이지 교체 알고리즘은 FIFO, OPR, LRU, LFU, MFU등이 있다.

1. FIFO : 가장 간단한 교체 알고리즘, 물리 메모리에 들어온 페이지 순서대로 교체, 이해하기 쉽고 프로그래밍 하기도 쉽다. 중요도를 정할 수 없고, 우선도를 정할 수 없어서 페이지 부재율을 높일 수 있다. Belady의 모순(페이지 프레임이 늘어도 페이지 부재가 더 많이 발생하는 모순)이 발생 가능하다.
2. 최적 페이지 교체(Optimal Page Replacement) : Belady 모순이 발생하지 않고 모든 알고리즘 중 가장 낮은 페이지 부재율을 가진 알고리즘, 앞으로 가장 오래 사용 되지 않을 페이지를 우선 교체(비교 연구), 가장 낮은 부재율 보장, 구현의 어려움, 미래 시행 계획을 파악할 방법이 부재.
3. LRU(Least-Recently-Used) : 가장 오래 사용 되지 않은 페이지를 우선 교체, 대체적으로 FIFO 보다는 우수하고, OPT보다는 못하다.
4. LFU(Least-Frequently-Used) : 참조 횟수가 가정 적은 페이지를 우선 교체, 프로세스 페이지 참조가 캐쉬 되기에 사용하지 않는 기능이 계속 메모리에 머물 수 있고, OPT교체를 제대로 근사하지 못하기에 사용 빈도가 낮다.
5. MFU(Most-Frequently Used) : 참조 횟수가 가장 많은 페이지를 우선 교체, OPT를 제대로 근사 하지 못해서 사용 빈도가 낮다. 
